{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary Python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "quality = pd.read_csv(\"quality.csv\")\n",
    "quality_data = np.array(quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training-testing sets\n",
    "X = quality_data[:,1:-1]\n",
    "y = quality_data[:,-1]\n",
    "y = y.astype('int')\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state= 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = linear_model.LogisticRegression()\n",
    "Xlr_train = np.hstack((X_train[:,3].reshape(98, 1),X_train[:,4].reshape(98, 1)))\n",
    "Xlr_test = np.hstack((X_test[:,3].reshape(33, 1),X_test[:,4].reshape(33, 1)))\n",
    "\n",
    "model1.fit(Xlr_train,y_train.astype('int'))\n",
    "print('Coefficient: ', model1.coef_)\n",
    "print('Intercept: ', model1.intercept_)\n",
    "\n",
    "ylr_pred = model1.predict(Xlr_test)\n",
    "ylr_pred_prob =  model1.predict_proba(Xlr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "CM_lr = confusion_matrix(y_test, ylr_pred)\n",
    "print(CM_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate out-of-sample AUC\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test.astype('int'), ylr_pred_prob[:,1])\n",
    "#Draw the ROC curve\n",
    "plt.plot(fpr,tpr,marker = 'o')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the OfficeVisits and Narcotics as covariates in KNN\n",
    "OfficeVisits_train = ((X_train[:,3] - np.mean(X_train[:,3]))/np.std(X_train[:,3])).reshape(-1,1)\n",
    "Narcotics_train = ((X_train[:,3] - np.mean(X_train[:,3]))/np.std(X_train[:,3])).reshape(-1,1)\n",
    "OfficeVisits_test = ((X_test[:,3] - np.mean(X_test[:,3]))/np.std(X_test[:,3])).reshape(-1,1)\n",
    "Narcotics_test = ((X_test[:,3] - np.mean(X_test[:,3]))/np.std(X_test[:,3])).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the covariates of training and testing sets\n",
    "X1_train = np.hstack((OfficeVisits_train,Narcotics_train))\n",
    "X1_test = np.hstack((OfficeVisits_test,Narcotics_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X1_train.shape)\n",
    "print(X1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train the knn model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3,metric='euclidean')\n",
    "knn.fit(X1_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the overall accuracy of knn model\n",
    "OA_knn = knn.score(X1_test, y_test) \n",
    "print(OA_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "y_pred = knn.predict(X1_test)\n",
    "\n",
    "CM_knn = confusion_matrix(y_test, y_pred)\n",
    "print(CM_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train-Validate-Test Triplet for the healthcare quality case\n",
    "X1_trainval = X1_train\n",
    "y_trainval = y_train\n",
    "\n",
    "#Split the training and validation set\n",
    "X1_train, X1_val, y_train, y_val = train_test_split(X1_trainval, y_trainval,test_size=0.33)\n",
    "\n",
    "#Find out which model has the highest validation accuracy\n",
    "val_scores = []\n",
    "neighbors = np.arange(1, 15, 2)\n",
    "for i in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X1_train, y_train)\n",
    "    val_scores.append(knn.score(X1_val, y_val))\n",
    "    \n",
    "print(\"Best validation accuracy: {:.3f}\".format(np.max(val_scores)))\n",
    "best_n_neighbors = neighbors[np.argmax(val_scores)]\n",
    "print(\"Best number of neighbors: {}\".format(best_n_neighbors))\n",
    "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
    "\n",
    "#Test the performance of the \"best\" on the testing set \n",
    "knn.fit(X1_trainval, y_trainval)\n",
    "print(\"Test-set accuracy: {:.3f}\".format(knn.score(X1_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##k-fold Cross Validation for healthcare quality case\n",
    "\n",
    "#import the CV package\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Cross Validation with number of folds k=3\n",
    "cross_val_scores = []\n",
    "for i in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    scores = cross_val_score(knn, X1_trainval, y_trainval, cv=6)\n",
    "    cross_val_scores.append(np.mean(scores))\n",
    "    \n",
    "    \n",
    "print(\"Best cross-validation accuracy: {:.3f}\".format(np.max(cross_val_scores)))\n",
    "best_n_neighbors = neighbors[np.argmax(cross_val_scores)]\n",
    "print(\"Best number of neighbors: {}\".format(best_n_neighbors))\n",
    "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
    "knn.fit(X1_trainval, y_trainval)\n",
    "print(\"Test-set score: {:.3f}\".format(knn.score(X1_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Lasso and Ridge Regression\n",
    "\n",
    "#Load the boston housing data set\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb = boston.data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_b = linear_model.Lasso(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_b.fit(Xb,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lasso_b.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_b = linear_model.Ridge(alpha=1)\n",
    "ridge_b.fit(Xb,yb)\n",
    "print(ridge_b.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_b = linear_model.LinearRegression()\n",
    "linear_b.fit(Xb,yb)\n",
    "print(linear_b.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning the parameter alpha for lasso and ridge regressions\n",
    "\n",
    "#Import necessary package\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {'alpha': np.logspace(-3, 0, 13)}\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lasso = GridSearchCV(linear_model.Lasso(), param_grid, cv=10)\n",
    "grid_lasso.fit(Xb, yb)\n",
    "print(grid_lasso.best_params_)\n",
    "print('Best R squared in Lasso Regression: %.2f' %grid_lasso.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ridge = GridSearchCV(linear_model.Ridge(), param_grid, cv=10)\n",
    "grid_ridge.fit(Xb, yb)\n",
    "print(grid_ridge.best_params_)\n",
    "print('Best R squared in Ridge Regression: %.2f' %grid_ridge.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
